# Snowflake to Cloud Storage Action


Description
-----------
Unloads data from a [Snowflake](https://www.snowflake.com/product/) table to an internal or external cloud storage location (stage).

Plugin works on top of COPY INTO. Please see its 
[docs](https://docs.snowflake.com/en/sql-reference/sql/copy-into-location.html)
for more information.

Configuration
-------------

### Basic

**Label:** Label for UI.

**Account Name:** Snowflake account name and region and possibly a cloud specifier. (Part of the URL you use to 
log in to Snowflake, minus the "snowflakecomputing.com"). E.g. "myaccount.us-central1.gcp".

**Database:** Database that contains the source table.

**Schema:** Schema that contains the source table.

**Warehouse:** Warehouse to use for the data unload operation (i.e. compute resources).

**Role:** Role to use (e.g. `ACCOUNTADMIN`).

**Source Type:** The source of the data to unload. Possible values: `From Table`, `From Query`.

**Source Table:** Table to load data from.

**Source Query:** SQL query which specifies an explicit set of fields/columns (separated by commas) 
to unload from the table.

**Destination Path:** Internal or external location where the files are saved.

Examples of internal locations formats:
```
@~[/{path}]
@[{namespace}.]{int_stage_name}[/{path}]
@[{namespace}.]%{table_name}[/{path}]
```

Examples of external locations formats:
```
@[{namespace}.]{ext_stage_name}[/{path}]
s3://{bucket}[/{path}]
gcs://{bucket}[/{path}]
azure://{account}.blob.core.windows.net/{container}[/{path}]
```

### Credentials

**Username:** Username to use to connect to your Snowflake account.

**Password:** Password to use to connect to your Snowflake account. Not necessary for key pair or OAuth2 authentication.

### Key Pair Authentication

**Key Pair Authentication Enabled:** If true, plugin will perform key pair authentication.

**Private Key:** Private key contents.

**Key File Passphrase:** Passphrase for the private key file.

### OAuth2

To use OAuth2, user must create a snowflake security integration for it.
For more info see [Introduction to OAuth in Snowflake](https://docs.snowflake.com/en/user-guide/oauth-intro.html)

**OAuth2 Enabled:** If true, plugin will perform OAuth2 authentication.

**Client ID:** Client id obtained via system function 
[SYSTEM$SHOW_OAUTH_CLIENT_SECRETS](https://docs.snowflake.com/en/sql-reference/functions/system_show_oauth_client_secrets.html)

**Client Secret:** Client id obtained via system function 
[SYSTEM$SHOW_OAUTH_CLIENT_SECRETS](https://docs.snowflake.com/en/sql-reference/functions/system_show_oauth_client_secrets.html)

**Refresh Token:** Token used to receive accessToken, which is end product of OAuth2. Must be generated by user.

### Cloud Provider Parameters
More information on this section can be found on 
[the official site](https://docs.snowflake.com/en/sql-reference/sql/copy-into-location.html#additional-cloud-provider-parameters)

**Use Cloud Provider Parameters:** If true, plugin will use cloud provider parameters to authenticate to destination 
path. Required only for unloading to external private/protected cloud storage location; not required for public 
buckets/containers.

**Cloud Provider:** Cloud provider name. Possible values: `azure`, `gcs`, `s3`.

**Storage Integration:** Specifies the name of the storage integration used to delegate authentication responsibility 
for external cloud storage to a Snowflake identity and access management (IAM) entity. For more details, see 
[CREATE STORAGE INTEGRATION](https://docs.snowflake.com/en/sql-reference/sql/create-storage-integration.html).
                         
Note. We highly recommend the use of storage integrations. This avoids the need to supply cloud storage 
when unloading data.

---

#### Amazon S3 specific parameters:

The credentials you specify depend on whether you associated the Snowflake access permissions 
for the bucket with an AWS IAM (Identity & Access Management) user or role:

**Key Id:** Amazon key ID.

**Secret Key:** Amazon secret key.

**Token:** Amazon token.

---

#### Microsoft Azure specific parameters:

**SAS Token:** SAS (shared access signature) token for connecting to Azure and accessing the 
private/protected container where the files containing data are saved. Credentials are generated by Azure.

---

**Files Encrypted:** If true, plugin will perform loading from encrypted files.

**Encryption type:** Encryption of the files. Possible values:
- `AWS_CSE:` Client-side encryption (requires a `Master Key` value). Currently, the client-side master key 
you provide can only be a symmetric key. Note that, when a `Master Key` value is provided, Snowflake assumes 
TYPE = AWS_CSE (i.e. when a MASTER_KEY value is provided, TYPE is not required).
- `AWS_SSE_S3:` Server-side encryption that requires no additional encryption settings.
- `AWS_SSE_KMS:` Server-side encryption that accepts an optional `KMS Key Id` parameter.
- `AZURE_CSE:` Client-side encryption; requires a `Master Key` value.
- `GCS_SSE_KMS:` Server-side encryption that accepts an optional `KMS Key Id` parameter.

**Master Key:** Client-side master key that Snowflake uses to encrypt the files containing the 
unloaded data. The master key must be a 128-bit or 256-bit key in Base64-encoded form. Required by
`AWS_CSE` and `AZURE_CSE` encryption types.

**KMS Key Id:** ID for the KMS-managed key that is used to encrypt files unloaded into the bucket. 
If no value is provided, your default KMS key ID is used to encrypt files on unload. The value is optionally
and used by the following encryption types: `AWS_SSE_KMS`, `GCS_SSE_KMS`.

### File Format

**File Format Filtering Policy:** Policy used to filter source files. Possible value:
- `Undefined` Do not filter the files.
- `By File Type` Filter using `Format Type` configuration.
- `By Existing Format Specification` Filter by existing format saved in Snowflake.

**Format Name:** Existing named file format to use for loading data into the table. The named file 
format determines the format type (CSV, JSON, etc.), as well as any other format options, for the data files. 
For more information, see [CREATE FILE FORMAT.](https://docs.snowflake.com/en/sql-reference/sql/create-file-format.html)

**Format Type:** Type of files to load into the table. Supported values; CSV, JSON, AVRO, ORC, PARQUET, XML.

**Format Type Options:** Depending on the file format type specified (`Format Type` property) 
you can include one or more of the format-specific options. Find the options list 
[here.](https://docs.snowflake.com/en/sql-reference/sql/copy-into-location.html#format-type-options-formattypeoptions).

### Advanced

**Copy Options:** List of copy options. Find them 
[here.](https://docs.snowflake.com/en/sql-reference/sql/copy-into-location.html#copy-options-copyoptions)

**Include Header:** Specifies whether to include the table column headings in the output files. The column headings 
are included in every file.

**Connection Arguments:** List of arbitrary string tag/value pairs as connection arguments. See: [JDBC Driver Connection String.](https://docs.snowflake.com/en/user-guide/jdbc-configure.html#jdbc-driver-connection-string)
